# ML Service Environment Variables

# API Keys (Required for LLM features)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Service Configuration
ML_SERVICE_PORT=8002
ENVIRONMENT=development

# Model Configuration
MODEL_PATH=./models
CACHE_DIR=./.cache

# Logging
LOG_LEVEL=info
LOG_FORMAT=json

# Performance
MAX_WORKERS=4
ENABLE_GPU=false

# Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=900

# Feature Flags
ENABLE_ADVANCED_REASONING=true
ENABLE_FALLACY_DETECTION=true
ENABLE_SEMANTIC_ANALYSIS=true
